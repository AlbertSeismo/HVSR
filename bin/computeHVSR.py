#!/anaconda/3/bin/python
# -*- coding: UTF-8 -*-
#
################################################################################################
#
# NAME: computeHVSR.py - a Python script that uses IRIS DMC's MUSTANG noise-psd/pdf web services
#       to compute horizontal-to-vertical spectral ratio (HVSR)
#
# Copyright (C) 2017  Product Team, IRIS Data Management Center
#
#    This is a free software; you can redistribute it and/or modify
#    it under the terms of the GNU Lesser General Public License as
#    published by the Free Software Foundation; either version 3 of the
#    License, or (at your option) any later version.
#
#    This script is distributed in the hope that it will be useful, but
#    WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
#    Lesser General Public License (GNU-LGPL) for more details.  The
#    GNU-LGPL and further information can be found here:
#    http://www.gnu.org/
#
#    You should have received a copy of the GNU Affero General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
#
# INPUTS:
#    Script expects a configuration parameter file under the "param" directory. 
#    the parameter file's name is the same as this scripts name with "_param" appended.
#    Script also expects a station baseline file as generated by the getStationChannelBaseline.py
#    script.
#
# OUTPUTS:
#    - HVSR values
#    - HVSR plots
#    - SESAME 2004 parameters
#
# USAGE:
#              network station location channel list     start date       end date  plot(1/0) plot      plot accepted     verbose    y-axis x-axis type     break start-end
#                  |       |       |    |                |                 |             | rejected     accepted    plot  output(1/0)  max      |           interval into "n"
#                  |       |       |    |                |                 |             |   PSDs(1/0)   PSDs(1/0)  PDFs(1/0) |         |       |              | segments
#                  |       |       |    |                |                 |             |       |         |        |         |         |       |              |
#   computeHVSR.py net=TA sta=TCOL loc= chan=BHZ,BHN,BHE start=2013-01-01 end=2013-01-01 plot=1 plotbad=0 plotpsd=0 plotpdf=1 verbose=1 ymax=5 xtype=frequency n=1
#
# HISTORY:
#
version = "R.2017332"
#
#    2017-11-28 IRIS DMC Product Team (Manoch): public release R.2017332
#    2017-05-21 IRIS DMC Product Team (Manoch): R.2017141
#    2017-03-12 IRIS DMC Product Team (Manoch): created R.2017071
#
# REFERENCE:
#   Guidelines for the Implementation of the H/V Spectral Ratio Technique on Ambient Vibrations, December 2004
#   SESAME European research project WP12 – Deliverable D23.12, European Commission – Research General Directorate
#   Project No. EVG1-CT-2000-00026 SESAME.
#   ftp://ftp.geo.uib.no/pub/seismo/SOFTWARE/SESAME/USER-GUIDELINES/SESAME-HV-User-Guidelines.pdf
#
################################################################################################
#
# parameters to set initially
#
################################################################################################
maxRank = 0
greekChar = {'sigma':u"\u03C3",'epsilon':u"\u03B5",'teta':  u"\u03B8"}
import operator
import numpy as np
import time
t0 = time.time()
channelOrder = {'Z':0,'1':1,'N':1,'2':2,'E':2}

################################################################################################
#
#  usage message
#
################################################################################################
#
def usage():
   print ("\n\nUSAGE("+version+"):\n\n")
   print ("              network station location channel list     start date       end date  plot(1/0) plot      plot accepted     verbose    y-axis x-axis type     break start-end")
   print ("                  |       |       |    |                |                 |             | rejected     accepted    plot  output(1/0)  max      |           interval into \"n\"")
   print ("                  |       |       |    |                |                 |             |   PSDs(1/0)   PSDs(1/0)  PDFs(1/0) |         |       |              | segments")
   print ("                  |       |       |    |                |                 |             |       |         |        |         |         |       |              |")
   print ("   computeHVSR.py net=TA sta=TCOL loc= chan=BHZ,BHN,BHE start=2013-01-01 end=2013-01-01 plot=1 plotbad=0 plotpsd=0 plotpdf=1 verbose=1 ymax=5 xtype=frequency n=1")
   print ("")
   print ("any parameter given on the command line will override the one defined in the parameter file")
   print ("\n\n\n")

################################################################################################
#
# timeIt - compute elapsed time since the last cal
#
################################################################################################
#
def timeIt(t0):
   t1 = time.time()
   dt = t1 - t0
   t = t0
   if dt > 0.05:
     print(" ".join(["[TIME]",str(dt),"seconds"]))
     t = t1
   return t

################################################################################################
#
#  break an interval to date ranges
#  this is used to avoid large requests that get rejected
#
################################################################################################
#
def dateRange(start, end, intv):
    dateList = []
    from datetime import datetime
    start = datetime.strptime(start,"%Y-%m-%d")
    end = datetime.strptime(end,"%Y-%m-%d")
    diff = (end  - start ) / intv
    for i in range(intv):
        dateList.append((start + diff * i).strftime("%Y-%m-%d"))
    dateList.append(end.strftime("%Y-%m-%d"))
    return dateList

###############################################################################################
#
#  print a report of peak parameters
#
################################################################################################
#
def printPeakReport(stationHeader,reportHeader,peak,reportinfo,minRank):
   index = []
   rank  = []

   if reportinfo > 0:
      print("\n\nPeaks:")
      print("Parameters and ranking based on SESAME 2004 (A0: peak amplitude, f0: peak frequency):\n")
      print("- amplitude clarity conditions:")
      print("\t. there exist one frequency f-, lying between f0/4 and f0, such that A0 / A(f-) > 2")
      print("\t. there exist one frequency f+, lying between f0 and 4*f0, such that A0 / A(f+) > 2")
      print("\t. A0 > 2\n")
      print("- amplitude stability conditions:")
      print("\t. peak appear within +/-5% on H/V curves of mean +/- one standard deviation (f0+/f0-)")
      print("\t. "+greekChar['sigma']+"f lower than a frequency dependent threshold "+greekChar['epsilon']+"(f)")
      print("\t. "+greekChar['sigma']+"A lower than a frequency dependent threshold log "+greekChar['teta']+"(f)\n")
      #print("\n\n%s"%(reportHeader))
   for i in range(len(peak)):
      index.append(i)
      rank.append(peak[i]['Score'])
   listTmp = list(zip(rank, index))   
   listTmp.sort(reverse=True)

   if reportinfo > 0:
      print("\n%47s %10s %22s %12s %12s %32s %32s %27s %22s %17s"
             %("Net.Sta.Loc.Chan","    f0    ","        A0 > 2        ","     f-      ","    f+     ","     f0- within ±5% of f0 &     ","     f0+ within ±5% of f0       ",greekChar['sigma']+"f < "+greekChar['epsilon']+" * f0      ",greekChar['sigma']+"logH/V < log"+greekChar['teta']+"    ","   Score/Max.    "))
      print("%47s %10s %22s %12s %12s %32s %32s %27s %22s %17s\n" 
             %("================================================","==========","======================","============","============","================================","================================","===========================","======================","================="))

   peakVisible = []
   for i in range(len(listTmp)):
      index = listTmp[i][1]
      thisPeak = peak[index]
      if(float(thisPeak['Score']) < minRank):
         continue
      else:
         peakVisible.append(True)
      print("%47s %10.3f %22s %12s %12s %32s %32s %27s %22s %12d/%0d\n"%(stationHeader,thisPeak['f0'],thisPeak['Report']['A0'],thisPeak['f-'],thisPeak['f+'],thisPeak['Report']['P-'],thisPeak['Report']['P+'],thisPeak['Report']['Sf'],thisPeak['Report']['Sa'],thisPeak['Score'],maxRank))
   if len(listTmp) <= 0 or len(peakVisible) <= 0:
       print("%47s\n"%(stationHeader))

################################################################################################
#
# get run arguments
#
################################################################################################
#
def getArgs(argList):
   args = {}
   for i in range(1,len(argList)):
      key,value = argList[i].split('=')
      args[key] = value
   return args

################################################################################################
#
# get a run argument for the given key
#
################################################################################################
#
def getParam(args,key,msgLib,value,verbose=-1):
   if key in args.keys():
      if verbose >= 0: 
         print (key,args[key])
      return args[key]
   elif value is not None:
      return value
   else:
      msgLib.error("missing parameter "+key,1)
      usage()
      sys.exit()

################################################################################################
#
# check the PSD values to see if they are within the range
#
################################################################################################
#
def checkYRange(y,low,high):
   OK    = []
   NOTOK = []
   #
   # use subtract operator to see if y and low/high are crossing
   #
   for i in range(len(y)):
#      l = list(map(operator.sub,y[i],low))
      l = [a - b for a, b in zip(y[i], low)]
      if min(l) < 0 :
         NOTOK.append(i)
         continue

#      h = list(map(operator.sub,y[i],high))
      h = [a - b for a, b in zip(y[i], high)]
      if max(h) > 0 :
         NOTOK.append(i)
         continue

      OK.append(i)
         
   return (OK,NOTOK)

################################################################################################
#
# convert dB power to power
#
################################################################################################
#
def removeDb(dbValue):
   value = float(dbValue/10.0)
   return pow(10.0,value)

################################################################################################
#
# calculate HVSR
#
# We will undo setp 6 of MUSTANG processing as outlined below:
#    1. Dividing the window into 13 segments having 75% overlap
#    2. For each segment:
#       2.1 Removing the trend and mean
#       2.2 Apply a 10% sine taper
#       2.3 FFT
#    3. Calculate the normalized PSD
#    4. Average the 13 PSDs & scale to compensate for tapering
#    5. Frequency-smooth the averaged PSD over 1-octave intervals at 1/8-octave increments
#    6. Convert power to decibels
#
################################################################################################
#
def getHvsr(dBz,dB1,dB2):
   from scipy.stats import gmean 
   #
   # First convert dB to m/s**2 (the /Hz portion is not necessary since it will cancel out when 
   #       calculating ratios)
   #
   pz = math.sqrt(removeDb(float(dBz)))
   p1 = math.sqrt(removeDb(float(dB1)))
   p2 = math.sqrt(removeDb(float(dB2)))

   #
   # H mean - mean of horizontal power here we use geometric mean of power that translates to 
   #          RMS of amplitude (we could also have used arithmetic  mean)
   #
   h = gmean([p1,p2])
   #h = math.sqrt((p1*p1+p2*p2)/2.0)
   hvsr  = float(h/pz)
   return hvsr

################################################################################################
#
# find peaks
#
################################################################################################
#
def findPeaks(Y):

   # 
   # find the peaks
   #
   from scipy.signal import argrelextrema
   indexList = argrelextrema(np.array(Y), np.greater)

   return indexList[0]

################################################################################################
#
# initialize peaks
#
################################################################################################
#
def initPeaks(X,Y,indexList,hvsrBand,peakWaterLevel):
   peak    = []
   for i in indexList:
      if Y[i] > peakWaterLevel[i] and (X[i] >= hvsrBand[0] and X[i] <= hvsrBand[1]):
         peak.append({'f0':float(X[i]),'A0':float(Y[i]),'f-':None,'f+':None,'Sf':None,'Sa':None,'Score':0,'Report':{'A0':'','Sf':'','Sa':'','P+':'','P-':''}})
   return peak

################################################################################################
#
# test peaks for satisfying amplitude clarity conditions as outlined by SESAME 2004:
#     - there exist one frequency f-, lying between f0/4 and f0, such that A0 / A(f-) > 2
#     - there exist one frequency f+, lying between f0 and 4*f0, such that A0 / A(f+) > 2
#     - A0 > 2
#
################################################################################################
#
def checkClarity(X,Y,peak,rank=False):
   global maxRank

   # 
   # peaks with A0 > 2
   #
   if rank:
     maxRank += 1
   a0 = 2.0
   for i in range(len(peak)):
     
      if float(peak[i]['A0']) > a0:
         peak[i]['Report']['A0'] = "%10.2f > %0.1f %1s"%(peak[i]['A0'],a0,u'\u2713')
         peak[i]['Score'] += 1
      else:
         peak[i]['Report']['A0'] = "%10.2f > %0.1f  "%(peak[i]['A0'],a0)
   #
   # test each peak for clarity
   #
   if rank:
     maxRank += 1
   for i in range(len(peak)):
      peak[i]['f-'] = '-'
      for j in range(len(X)-1,-1,-1):
         #
         # there exist one frequency f-, lying between f0/4 and f0, such that A0 / A(f-) > 2
         #
         if (X[j] >= float(peak[i]['f0'])/4.0 and X[j] < float(peak[i]['f0'])) and float(peak[i]['A0'])/Y[j] > 2.0:
            peak[i]['f-']     = "%10.3f %1s"%(X[j],u'\u2713')
            peak[i]['Score'] += 1 
            break

   if rank:
      maxRank += 1
   for i in range(len(peak)):
      peak[i]['f+'] = '-'
      for j in range(len(X)):
         #
         # there exist one frequency f+, lying between f0 and 4*f0, such that A0 / A(f+) > 2
         #
         if (X[j] <= float(peak[i]['f0'])*4.0 and X[j] > float(peak[i]['f0'])) and float(peak[i]['A0'])/Y[j] > 2.0:
            peak[i]['f+']     = "%10.3f %1s"%(X[j],u'\u2713')
            peak[i]['Score'] += 1 
            break
         
   return peak
   
###############################################################################################
#
# test peaks for satisfying stability conditions as outlined by SESAME 2004:
#     - the peak should appear at the same frequency (within a percentage ± 5%) on the H/V
#       curves corresponding to mean + and – one standard deviation.
#
################################################################################################
#
def checkFreqStability(peak,peakm,peakp):
   global maxRank

   # 
   # check σf and σA
   #
   maxRank += 1

   foundm = []
   for i in range(len(peak)):
      dx = 1000000.
      foundm.append(False)
      peak[i]['Report']['P-'] = "- &"
      for j in range(len(peakm)):
         if abs(peakm[j]['f0'] - peak[i]['f0']) < dx:
            index = j
            dx = abs(peakm[j]['f0'] - peak[i]['f0'])
         if (peakm[j]['f0'] >= peak[i]['f0'] * 0.95 and peakm[j]['f0'] <= peak[i]['f0']* 1.05):
            peak[i]['Report']['P-'] = "%0.3f within ±5%s of %0.3f %1s"%(peakm[j]['f0'],'%',peak[i]['f0'],'&')
            foundm[i] = True
            break
      if peak[i]['Report']['P-'] == "-":
         peak[i]['Report']['P-'] = "%0.3f within ±5%s of %0.3f %1s"%(peakm[index]['f0'],'%',peak[i]['f0'],'&') 

   foundp = []
   for i in range(len(peak)):
      dx = 1000000.
      foundp.append(False)
      peak[i]['Report']['P+'] = "-"
      for j in range(len(peakp)):
         if abs(peakp[j]['f0'] - peak[i]['f0']) < dx:
            index = j
            dx = abs(peakp[j]['f0'] - peak[i]['f0'])
         if (peakp[j]['f0'] >= peak[i]['f0'] * 0.95 and peakp[j]['f0'] <= peak[i]['f0']* 1.05):
            if foundm[i]:
               peak[i]['Report']['P+'] = "%0.3f within ±5%s of %0.3f %1s"%(peakp[j]['f0'],'%',peak[i]['f0'],u'\u2713')
               peak[i]['Score'] += 1
            else:
               peak[i]['Report']['P+'] = "%0.3f within ±5%s of %0.3f %1s"%(peakp[index]['f0'],'%',peak[i]['f0'],' ') 
            break
      if peak[i]['Report']['P+'] == "-" and len(peakp) > 0:
         peak[i]['Report']['P+'] = "%0.3f within ±5%s of %0.3f %1s"%(peakp[index]['f0'],'%',peak[i]['f0'],' ') 
            
   return peak


###############################################################################################
#
# test peaks for satisfying stability conditions as outlined by SESAME 2004:
#     - σf lower than a frequency dependent threshold ε(f)
#     - σA (f0) lower than a frequency dependent threshold θ(f),
#
################################################################################################
#
def checkStability(stdf,peak,hvsrlogstd=False,rank=False):
   global maxRank

   # 
   # check σf and σA
   #
   if rank:
      maxRank += 2
   for i in range(len(peak)):
      peak[i]['Sf'] = stdf[i]
      peak[i]['Sa'] = hvsrlogstd[i]
      thisPeak = peak[i]
      if thisPeak['f0'] < 0.2:
         e = 0.25
         if stdf[i] < e * thisPeak['f0']:
            peak[i]['Report']['Sf'] = "%10.4f < %0.2f * %0.3f %1s"%(stdf[i],e,thisPeak['f0'],u'\u2713')
            thisPeak['Score'] +=1
         else:
            peak[i]['Report']['Sf'] = "%10.4f < %0.2f * %0.3f  "%(stdf[i],e,thisPeak['f0'])

         t = 0.48
         if hvsrlogstd[i] < t:
            peak[i]['Report']['Sa'] = "%10.4f < %0.2f %1s"%(hvsrlogstd[i],t,u'\u2713')
            thisPeak['Score'] +=1
         else:
            peak[i]['Report']['Sa'] = "%10.4f < %0.2f  "%(hvsrlogstd[i],t)

      elif thisPeak['f0'] >= 0.2 and thisPeak['f0'] < 0.5:
         e = 0.2
         if stdf[i] < e * thisPeak['f0']:
            peak[i]['Report']['Sf'] = "%10.4f < %0.2f * %0.3f %1s"%(stdf[i],e,thisPeak['f0'],u'\u2713')
            thisPeak['Score'] +=1
         else:
            peak[i]['Report']['Sf'] = "%10.4f < %0.2f * %0.3f  "%(stdf[i],e,thisPeak['f0'])

         t = 0.40
         if hvsrlogstd[i] < t:
            peak[i]['Report']['Sa'] = "%10.4f < %0.2f %1s"%(hvsrlogstd[i],t,u'\u2713')
            thisPeak['Score'] +=1
         else:
            peak[i]['Report']['Sa'] = "%10.4f < %0.2f  "%(hvsrlogstd[i],t)

      elif thisPeak['f0'] >= 0.5 and thisPeak['f0'] < 1.0:
         e = 0.15
         if stdf[i] < e * thisPeak['f0']:
            peak[i]['Report']['Sf'] = "%10.4f < %0.2f * %0.3f %1s"%(stdf[i],e,thisPeak['f0'],u'\u2713')
            thisPeak['Score'] +=1
         else:
            peak[i]['Report']['Sf'] = "%10.4f < %0.2f * %0.3f  "%(stdf[i],e,thisPeak['f0'])

         t = 0.3
         if hvsrlogstd[i] < t:
            peak[i]['Report']['Sa'] = "%10.4f < %0.2f %1s"%(hvsrlogstd[i],t,u'\u2713')
            thisPeak['Score'] +=1
         else:
            peak[i]['Report']['Sa'] = "%10.4f < %0.2f  "%(hvsrlogstd[i],t)

      elif thisPeak['f0'] >= 1.0 and thisPeak['f0'] <= 2.0:
         e = 0.1
         if stdf[i] < e * thisPeak['f0']:
            peak[i]['Report']['Sf'] = "%10.4f < %0.2f * %0.3f %1s"%(stdf[i],e,thisPeak['f0'],u'\u2713')
            thisPeak['Score'] +=1
         else:
            peak[i]['Report']['Sf'] = "%10.4f < %0.2f * %0.3f  "%(stdf[i],e,thisPeak['f0'])
        
         t = 0.25
         if hvsrlogstd[i] < t:
            peak[i]['Report']['Sa'] = "%10.4f < %0.2f %1s"%(hvsrlogstd[i],t,u'\u2713')
            thisPeak['Score'] +=1
         else:
            peak[i]['Report']['Sa'] = "%10.4f < %0.2f  "%(hvsrlogstd[i],t)

      elif thisPeak['f0'] > 0.2:
         e = 0.05
         if stdf[i] < e * thisPeak['f0']:
            peak[i]['Report']['Sf'] = "%10.4f < %0.2f * %0.3f %1s"%(stdf[i],e,thisPeak['f0'],u'\u2713')
            thisPeak['Score'] +=1
         else:
            peak[i]['Report']['Sf'] = "%10.4f < %0.2f * %0.3f  "%(stdf[i],e,thisPeak['f0'])

         t = 0.2
         if hvsrlogstd[i] < t:
            peak[i]['Report']['Sa'] = "%10.4f < %0.2f %1s"%(hvsrlogstd[i],t,u'\u2713')
            thisPeak['Score'] +=1
         else:
            peak[i]['Report']['Sa'] = "%10.4f < %0.2f  "%(hvsrlogstd[i],t)
   return peak         

###############################################################################################
#
# get PDF
#
################################################################################################
#
def getPDF(URL,verbose):

   xValues = []
   yValues = []
   X       = []
   Y       = []
   P       = []

   if verbose >= 0:
      msgLib.info('requesting:'+URL)
   try:
      link    = urllib.request.urlopen(URL)
   except urllib.error.HTTPError as e:
      gotData = False
      print ("\n")
      print(e.code)
      print(e.reason)
      if 'Too Large' in e.reason:
           print('Note: use the run argument "n" to split the requested date range to smaller intervals')
      #print(e.headers)
      msgLib.error("failed on target "+target+" "+URL,1)
      return (X,Y,P)

   if verbose >= 0:
      msgLib.info("PDF waiting for reply....")

   data     = link.read().decode()
   link.close()
   lines    = data.split('\n')
   lastFreq = ''
   gotData  = True
   lineCount        = 0
   nonBlankLastLine = 0
   if len(lines[-1].strip()) <= 0:
      nonBlankLastLine = 1
   for line in lines:
      lineCount += 1
      if len(line.strip()) <= 0:
         continue
      if line[0] == '#' or ',' not in line:
         continue
      (freq, power, hits) = line.split(',')
      if lastFreq == '':
         lastFreq = freq.strip()
         powerList = []
         powerList.append(float(power))
         hitsList  = []
         hitsList.append(int(hits))
      elif lastFreq == freq.strip():
         powerList.append(float(power))
         hitsList.append(int(hits))
      if lastFreq != freq.strip() or lineCount == len(lines) - nonBlankLastLine:
         totalHits=sum(hitsList)
         values = []
         yValues.append(np.array(hitsList)*100.0/totalHits)
         if xtype == "period":
            lastX = 1.0/float(lastFreq)
            xValues.append(lastX)
         else:
            lastX = float(lastFreq)
            xValues.append(lastX)
         for i in range(len(hitsList)):
            Y.append(float(powerList[i]))
            P.append(float(hitsList[i]) * 100.0 / float(totalHits))
            X.append(lastX)

         lastFreq = freq.strip()
         powerList = []
         powerList.append(float(power))
         hitsList  = []
         hitsList.append(int(hits))
   return (X,Y,P)

################################################################################################
#
# Main
#
################################################################################################

#
# set paths
#
import os, sys
hvsrDirectory  = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))

paramPath      = os.path.join(hvsrDirectory, 'param')
libPath        = os.path.join(hvsrDirectory, 'lib')

sys.path.append(paramPath)
sys.path.append(libPath)

import math, time
import urllib
import xml.etree.ElementTree as ET

#
# import the HVSR parameters and libraries
#
import fileLib as fileLib
import msgLib as msgLib
import computeHVSR_param as param

plotRows = 4

#
# set parameters
#
args = getArgs(sys.argv)
verbose = int(getParam(args,'verbose',msgLib,param.verbose))
if verbose >= 0:
   print ("\n",sys.argv[0], version)

reportinfo  = int(getParam(args,'reportinfo',msgLib,1,verbose))
channels    = getParam(args,'chan',msgLib,param.chan)
channelList = sorted(channels.split(','),reverse=True)
if len(channelList) < 3:
   msgLib.error('need 3 channels!',1)
   sys.exit()
sortedChannelList = channelList.copy()
for channel in channelList:
   sortedChannelList[channelOrder[channel[2]]] = channel

minRank     = float(getParam(args,'minrank',msgLib,param.minrank))
network     = getParam(args,'net',msgLib,None)
if network is None:
   msgLib.error('network not defined!',1)
   sys.exit()
station     = getParam(args,'sta',msgLib,None)
if station is None:
   msgLib.error('station not defined!',1)
   sys.exit()
location    = getParam(args,'loc',msgLib,None)
if location is None:
   msgLib.error('location not defined!',1)
   sys.exit()

start           = getParam(args,'start',msgLib,None)
startHour       = "T00:00:00"
startTime       = time.strptime(start, "%Y-%m-%d")
end             = getParam(args,'end',msgLib,None)
endHour         = "T00:00:00"
endTime         = time.strptime(end, "%Y-%m-%d")
n               = int(getParam(args,'n',msgLib,5))
dateList        = dateRange(start,end,n)
doPlot          = int(getParam(args,'plot',msgLib,param.plot))
plotPSD         = int(getParam(args,'plotpsd',msgLib,param.plotpsd))
plotPDF         = int(getParam(args,'plotpdf',msgLib,param.plotpdf))
plotBad         = int(getParam(args,'plotbad',msgLib,param.plotbad))
dayValuesPassed = [[],[],[]]
waterLevel      = float(getParam(args,'waterlevel',msgLib,param.waterlevel))
hvsrYlim        = param.hvsrylim
hvsrYlim[1]     = float(getParam(args,'ymax',msgLib,param.hvsrylim[1]))
xtype           = getParam(args,'xtype',msgLib,param.xtype)
hvsrBand        = getParam(args,'hvsrband',msgLib,param.hvsrband)
reportHeader    = '.'.join([network,station,location,'-'.join(sortedChannelList)])
stationHeader   = reportHeader
stationHeader   = ' '.join([stationHeader,start,end])
reportHeader   += ' '
reportHeader   += ' '.join(['from',start,'to',end])
plotTitle       = reportHeader
reportHeader   += '\n\n'


#
# turn off the display requirement if not needed
#
import matplotlib
if doPlot <= 0:
   if verbose >= 0:
      print ("PLOT OFF")
   matplotlib.use('agg')
else:
   from obspy.imaging.cm import pqlx

#
# one channel at a time
# the reverse sort order makes sure that we always have ?HZ first. Order of horizontals is not important
#
channelIndex = -1
for channel in sortedChannelList:
   channelIndex += 1
   xValues       = []
   psdValues     = []
   dayValues     = []
   pctLow        = []
   pctHigh       = []
   pctMid        = []

   target        = '.'.join([network,station,location,channel,"M"])
   label         = '.'.join([network,station,location,'PSDs'])
   labelHVSR     = '.'.join([network,station,location,'HVSR'])
   if verbose >= 0 :
      msgLib.info("requesting "+target+" from "+start+" to "+end)

   #
   # baseline files are required
   # we assume the baseline file has all the periods, so we use it as a reference
   #
   try:
      baselineFile = open(os.path.join(param.baselineDirectory,fileLib.baselineFileName(network,station,location,channel)),'r')
   except:
      msgLib.error("failed to read baseline file "+os.path.join(param.baselineDirectory,fileLib.baselineFileName(network,station,location,channel)),1)
      sys.exit()

   lines = baselineFile.read()
   baseline = lines.split('\n')
   for indexValue in range(0,len(baseline)):
      if len(baseline[indexValue].strip()) == 0:
         continue
      if baseline[indexValue].strip()[0] == '#':
         values = baseline[indexValue].strip().split()
         percentLow  = values[1]
         percentMid  = values[3]
         percentHigh = values[5]
         continue

      values = baseline[indexValue].split()
     
      xValues.append(float(values[0]))
      pctLow.append(float(values[1]))
      pctMid.append(float(values[2]))
      pctHigh.append(float(values[3]))
   baselineFile.close()

   #
   # get daily PSDs from MUSTANG
   #    Limit PSD segments starting between starttime (inclusive) and endtime (exclusive)
   # 
   pdfX = []
   pdfY = []
   pdfP = []
   for dateIndex in range(len(dateList)-1):
      URL = param.mustangPsdUrl+'target='+target+'&starttime='+dateList[dateIndex]+startHour+'&endtime='+dateList[dateIndex+1]+endHour+'&format=xml&correct=true'
      if verbose >= 0:
         msgLib.info('requesting:'+URL)
         t0 = timeIt(t0)
      try:
         link    = urllib.request.urlopen(URL)
      except urllib.error.HTTPError as e:
         if verbose >= 0:
            print (e.code)
            print(e.reason)
            if 'Too Large' in e.reason:
              print('Note: use the run argument "n" to split the requested date range to smaller intervals')
              print('Current "n" value is:',n)
            msgLib.error("failed on target "+target+" "+URL,1)
         continue

      if verbose > 0:
         msgLib.info("PSD waiting for reply....")

      tree = ET.parse(link)
      link.close()
      root = tree.getroot()

      if verbose > 0:
         msgLib.info(root.tag)
         requestStart = root.find('RequestedDateRange').find('Start').text
         requestEnd   = root.find('RequestedDateRange').find('End').text

      psds = root.find('Psds')

      allPsds = psds.findall('Psd')
      if verbose > 0:
         msgLib.info("PSD: "+str(len(allPsds)))
         t0 = timeIt(t0)

      for psd in allPsds:
         day     = psd.attrib['start'].split('T')[0]
         psdTime = time.strptime(day, "%Y-%m-%d")
         if psdTime < startTime or psdTime >= endTime:
            if verbose >= 0:
               msgLib.warning(sys.argv[0],"rejected PSD of "+psd.attrib['start'])
            continue
         allValues = psd.findall('value')
         
         X = []
         Y = []
         for value in allValues:
            X.append(float(value.attrib['freq']))
            Y.append(float(value.attrib['power']))

         #
         # check our previous assumption about samples, the X values must match xValues, above
         #
         if X != xValues:
            if verbose > 0:
               msgLib.warning(sys.argv[0]," ".join(["rejected",target,dateList[dateIndex],dateList[dateIndex+1],"for bad X"]))
         else:
            dayValues.append(day)
            psdValues.append(Y)

      if plotPDF > 0:
         (thisX,thisY,thisP) = getPDF(param.mustangPdfUrl+'target='+target+'&starttime='+dateList[dateIndex]+'&endtime='+dateList[dateIndex+1]+'&format=text',verbose)
         pdfX += thisX
         pdfY += thisY
         pdfP += thisP
         if verbose > 0:
            msgLib.info("PDF: "+str(len(pdfY)))
   if len(psdValues) <= 0:
      if verbose >= 0:
         msgLib.error(" ".join(["no PSDs found",dateList[dateIndex],dateList[dateIndex+1]]),1)
      sys.exit()
   else:
      if verbose >= 0:
         msgLib.info("total PSDs:"+str(len(psdValues)))
         t0 = timeIt(t0)

   #
   # work on PSDs
   #
   if channelIndex == 0:
      if doPlot > 0:
         if verbose >= 0:
            msgLib.info("PLOT PSD")
         import matplotlib.pyplot as plt
         from matplotlib.offsetbox import AnchoredText
         fig = plt.figure(figsize=(param.imageSize),facecolor="white")
         ax  = []
         fig.canvas.set_window_title(label)
         ax.append(plt.subplot(plotRows,1,channelIndex+1))

      dailyPSD       = [{},{},{}]
      medianDailyPSD = [{},{},{}]
   else:
      if doPlot > 0:
         ax.append(plt.subplot(plotRows,1,channelIndex+1, sharex=ax[0]))

   #
   # go through all PSDs and reject the "bad" ones based on the station baseline
   #
   if verbose > 0:
      msgLib.info("CLEAN UP "+str(len(psdValues))+" PSDs")
   (ok,notok) = checkYRange(psdValues,pctLow,pctHigh)
   reportHeader += ' '.join(['Channel',channel,str(len(psdValues)),"PSDs,",str(len(ok)),'accepted and',str(len(notok)),'rejected','\n'])
   if verbose > 0:
      t0 = timeIt(t0)
      msgLib.info("FLAG BAD PSDs")
   for i in range(len(ok)):
         index = ok[i]
         day   = dayValues[index]
         psd   = psdValues[index]
         if day not in dailyPSD[channelIndex].keys():
            dailyPSD[channelIndex][day] = []
         dailyPSD[channelIndex][day].append(psd)
         if dayValues[index] not in dayValuesPassed[channelIndex]:
            dayValuesPassed[channelIndex].append(day)
   if verbose > 0:
      t0 = timeIt(t0)
   #
   # plot the "bad" PSDs in gray
   #
   if doPlot > 0:
      if plotBad > 0:
         msgLib.info("PLOT BAD PSDs")
         for i in range(len(notok)):
            plt.semilogx(np.array(xValues), psdValues[notok[i]], c='gray')
         if verbose >= 0:
            t0 = timeIt(t0)

      if plotPSD > 0:
         #
         # plot the "good" PSDs in green
         #
         if verbose > 0:
            msgLib.info("PLOT GOOD PSDs")
         for i in range(len(ok)):
            plt.semilogx(np.array(xValues), psdValues[ok[i]], c='green')
         if verbose >= 0:
            t0 = timeIt(t0)
      elif plotPDF > 0:
         # define the colormap
         #cmap = plt.cm.jet
         # extract all colors from the .jet map
         #cmaplist = [cmap(i) for i in range(cmap.N)]
         # force the first color entry to be grey
         #cmaplist[0] = "mediumorchid"
         # create the new map
         #cmap = cmap.from_list('Custom cmap', cmaplist, cmap.N)
         cmap = pqlx

         ok      = []
         im = plt.scatter(pdfX,pdfY,c=pdfP, s=46.5, marker = '_',  linewidth=param.lw, edgecolor='face', cmap=cmap, alpha=param.alpha)
         ax[channelIndex].set_xscale('log')

      if verbose > 0:
         msgLib.info("TUNE PLOTS")
      if verbose >= 0:
         t0 = timeIt(t0)
      plt.semilogx(np.array(xValues),pctHigh,c='yellow',label=str(percentHigh)+'%')
      plt.semilogx(np.array(xValues),pctMid,c='red',label=str(percentMid)+'%')
      plt.semilogx(np.array(xValues),pctLow,c='orange',label=str(percentLow)+'%')
      plt.semilogx((param.hvsrXlim[0],param.hvsrXlim[0]),param.yLim,c='black')
      plt.semilogx((param.hvsrXlim[1],param.hvsrXlim[1]),param.yLim,c='black')
      p1 = plt.axvspan(param.xLim[xtype][0], param.hvsrXlim[0], facecolor='#909090', alpha=0.5)
      p2 = plt.axvspan(param.hvsrXlim[1], param.xLim[xtype][1], facecolor='#909090', alpha=0.5)
      #plt.title(" ".join([target,start,'to',end]))
      plt.ylim(param.yLim)
      plt.xlim(param.xLim[xtype])
      plt.ylabel(param.yLabel)
      plt.legend(loc='lower left')
      if len(ok) <= 0:
         anchored_text = AnchoredText(' '.join(['.'.join([network,station,location,channel]),"{:,d}".format(len(psdValues)),'PSDs']), loc=2)
      else:
         anchored_text = AnchoredText(' '.join(['.'.join([network,station,location,channel]),"{:,d}".format(len(ok)),'out of',"{:,d}".format(len(psdValues)),'PSDs']), loc=2)
      ax[channelIndex].add_artist(anchored_text)

      # create a second axes for the colorbar
      if plotPDF > 0:
         ax2 = fig.add_axes([0.92, 0.1, 0.01, 0.8])
         fig.colorbar(im, ax2, orientation='vertical')
         ax2.set_ylabel('Probability (%)', size=9, rotation=270, labelpad=7)
         plt.clim(param.pMin,param.pMax)

   #
   # compute and save the median daily PSD for HVSR computation
   #
   if verbose > 0:
      msgLib.info("SAVE MEDIAN DAILY")
   for day in (dayValuesPassed[channelIndex]):#dailyPSD[channelIndex].keys()):
       #medianDailyPSD[channelIndex][day] = np.percentile(list(zip(*dailyPSD[channelIndex][day])),50,axis=1)
       medianDailyPSD[channelIndex][day] = np.percentile(dailyPSD[channelIndex][day],50,axis=0)

#
# HVSR computation
#
if verbose > 0:
   msgLib.info("HVSR computation")
if verbose >= 0:
   t0 = timeIt(t0)

#
# find the unique days between all channels
#
d = dayValuesPassed[0]
for i in range(1,len(dayValuesPassed)):
   d += dayValuesPassed[i]
dayValuesPassed = set(d) # unique days

hvsr            = []
peakWaterLevel  = []
hvsrp           = []
peakWaterLevelp = []
hvsrp2          = []
hvsrm           = []
waterLevelm     = []
peakWaterLevelm = []
hvsrm2          = []
hvsrstd         = []
hvsrlogstd      = []
outFile         = open (os.path.join (param.hvsrDirectory, fileLib.hvsrFileName(network,station,location,start,end)), "w")
count           = -1

#
# compute one x-value (period or frequency) at a time to also compute standard deviation
#
outFile.write("frequency HVSR HVSR+1STD HVSR-1STD\n")
for j in range(len(xValues)):
   missing = 0
   hvsrTmp = []

   for day in sorted(dayValuesPassed):
      #
      # must have all 3 channels, compute HVSR for that day
      #
      if day in medianDailyPSD[0].keys() and day in medianDailyPSD[1].keys() and day in medianDailyPSD[2].keys():
         hvsr0 = getHvsr(medianDailyPSD[0][day][j],medianDailyPSD[1][day][j],medianDailyPSD[2][day][j])
         hvsrTmp.append(hvsr0)
      else:
         missing += 1
         if verbose > 0:
            msgLib.warning(sys.argv[0], day+" missing component, skipped!")
         continue

   count +=1
   peakWaterLevel.append(waterLevel)
   if len(hvsrTmp) > 0:
      hvsr.append(np.mean(hvsrTmp))
      hvsrstd.append(np.std(hvsrTmp))
      hvsrlogstd.append(np.std(np.log10(hvsrTmp)))
      hvsrp.append(hvsr[-1] + hvsrstd[-1])
      peakWaterLevelp.append(waterLevel + hvsrstd[-1])
      hvsrp2.append(hvsr[-1] * math.exp(hvsrlogstd[count]))
      hvsrm.append(hvsr[-1] - hvsrstd[-1])
      peakWaterLevelm.append(waterLevel - hvsrstd[-1])
      hvsrm2.append(hvsr[-1] / math.exp(hvsrlogstd[-1]))
      #outFile.write(str(xValues[count])+"  "+str(hvsr[-1])+"  "+str(hvsrp[-1])+"  "+str(hvsrm[-1])+"\n")
      outFile.write("%s %0.3f %0.3f %0.3f\n"%(str(xValues[count]),float(hvsr[-1]),float(hvsrp[-1]),float(str(hvsrm[-1]))))
outFile.close()

#
# compute day at a time to also compute frequency standard deviation
#
missing = 0
hvsrPeaks   = [] # this holds the peaks for individual HVSRs that will contribute to the final HVSR. It will be used to find Sigmaf

for day in sorted(dayValuesPassed):
   hvsrTmp = []
   for j in range(len(xValues)):
      if day in medianDailyPSD[0].keys() and day in medianDailyPSD[1].keys() and day in medianDailyPSD[2].keys():
         hvsr0 = getHvsr(medianDailyPSD[0][day][j],medianDailyPSD[1][day][j],medianDailyPSD[2][day][j])
         hvsrTmp.append(hvsr0)
      else:
         if verbose > 0:
            msgLib.warning(sys.argv[0], day+" missing component, skipped!")
         missing += 1
         continue
   if not np.isnan(np.sum(hvsrTmp)):
      hvsrPeaks.append(findPeaks(hvsrTmp)) 

reportHeader += '\n'
reportHeader += ' '.join([str(missing),'PSDs are missing one or more components\n'])

#
# find  the relative extrema of hvsr
#
if not np.isnan(np.sum(hvsr)):
   indexList = findPeaks(hvsr)
else:
   indexList = []

stdf = []
for index in indexList:
   point = []
   for j in range(len(hvsrPeaks)):
      p = None
      for k in range(len(hvsrPeaks[j])):
         if p is None:
            p = hvsrPeaks[j][k]
         else:
            if abs(index-hvsrPeaks[j][k]) < abs(index-p):
               p = hvsrPeaks[j][k]
      if p is not None:
         point.append(p)
   point.append(index)
   v = []
   for l in range(len(point)):
      v.append(xValues[point[l]])
   stdf.append(np.std(v))
         
peak  = initPeaks(xValues,hvsr,indexList,hvsrBand,peakWaterLevel)
peak  = checkClarity(xValues,hvsr,peak,True)

#
# find  the relative extrema of hvsrp (hvsr + 1 standard deviation)
#
if not np.isnan(np.sum(hvsrp)):
   indexp = findPeaks(hvsrp)
else:
   indexp = []

peakp  = initPeaks(xValues,hvsrp,indexp,hvsrBand,peakWaterLevelp)
peakp  = checkClarity(xValues,hvsrp,peakp)

#
# find  the relative extrema of hvsrp (hvsr - 1 standard deviation)
#
if not np.isnan(np.sum(hvsrm)):
   indexm = findPeaks(hvsrm)
else:
   indexm = []

peakm  = initPeaks(xValues,hvsrm,indexm,hvsrBand,peakWaterLevelm)
peakm  = checkClarity(xValues,hvsrm,peakm)

peak   = checkStability(stdf,peak,hvsrlogstd,True)
peak   = checkFreqStability(peak,peakm,peakp)


if doPlot > 0 and len(hvsr)>0:
   plt.suptitle(plotTitle)
   ax.append(plt.subplot(plotRows,1,4))
   plt.semilogx(np.array(xValues),hvsr,lw=1,c='b')
   plt.semilogx(np.array(xValues),hvsrp,c='r',lw=1,ls='--')
   plt.semilogx(np.array(xValues),hvsrm,c='r',lw=1,ls='--')
   #plt.semilogx(np.array(xValues),hvsrp2,c='r',lw=1,ls='--')
   #plt.semilogx(np.array(xValues),hvsrm2,c='r',lw=1,ls='--')
   plt.ylabel(param.hvsrYlabel)

   plt.xlim(param.hvsrXlim)
   ax[-1].set_ylim(hvsrYlim)
   plt.xlabel(param.xLabel[xtype])

   for i in range(len(peak)):
      plt.semilogx(peak[i]['f0'],peak[i]['A0'],marker='o',c='r')
      plt.semilogx((peak[i]['f0'],peak[i]['f0']),(hvsrYlim[0],peak[i]['A0']),c='red')
      if stdf[i] < float(peak[i]['f0']) :
         dz = stdf[i]
         plt.axvspan(float(peak[i]['f0']) - dz,float(peak[i]['f0']) + dz, facecolor='#909090', alpha=0.5)
         plt.semilogx((peak[i]['f0'],peak[i]['f0']),(hvsrYlim[0],hvsrYlim[1]),c='#dcdcdc',lw=0.5)

   plt.savefig(os.path.join(param.imageDirectory+"/"+fileLib.hvsrFileName(network,station,location,start,end)).replace(".txt",".png"),dpi=param.imageDpi)

printPeakReport(stationHeader,reportHeader,peak,reportinfo,minRank)

if doPlot > 0:
   if verbose >= 0:
      print ("SHOW")
   plt.show()
